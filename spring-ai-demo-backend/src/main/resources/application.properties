spring.application.name=spring-ai-demo

spring.ai.ollama.chat.options.model=deepseek-r1:7b
# this will increase memory usage quite a bit, but looks
# like changing it really does increase the context window, no
# need for custom ollama builds anymore
spring.ai.ollama.chat.options.num-ctx=32768
#spring.ai.ollama.chat.options.model=deepseek-r1-32768:7b
#spring.ai.ollama.chat.options.model=deepseek-r1:1.5b

spring.datasource.url=jdbc:postgresql://localhost:5436/spring-ai-demo-db
spring.datasource.username=postgres
spring.datasource.password=xxx
spring.datasource.driver-class-name=org.postgresql.Driver

spring.ai.vectorstore.pgvector.index-type=HNSW
spring.ai.vectorstore.pgvector.distance-type=COSINE_DISTANCE

# needs to match what we set when creating the vector table
# also should be based on the embedding used which (mxbai-embed-large:latest by default)
# according to `ollama show mxbai-embed-large:latest`, embedding length is 1024
spring.ai.vectorstore.pgvector.dimensions=1024


#spring.ai.ollama.embedding.options.model=nomic-embed-text:latest
#spring.ai.vectorstore.pgvector.dimensions=768

# not sure if this is needed or indeed doing anything
spring.ai.ollama.embedding.options.max-tokens=16000
#spring.ai.embedding.transformer.batch.single-document-max-token-count=8000
#spring.ai.embedding.transformer.batch.max-token-count=16000

